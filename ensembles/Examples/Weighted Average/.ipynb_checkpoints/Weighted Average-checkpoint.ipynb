{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ensembles as en\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from sklearn import datasets, linear_model, preprocessing, grid_search\n",
    "from sklearn.preprocessing import Imputer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, accuracy_score, \\\n",
    "mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials \n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from functools import partial\n",
    "np.random.seed(1338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6b6b7728a4b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\\ndata_test = en.data_import(Data, label_output='y')\\nprint('Training Data',Data.shape)\\nprint('Test Data',data_test.shape)\\n\\nen.metric_set('roc_auc_score')\\n\\n#Hyper Parameter Optimisation (max_depth and eta)\\nparam_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\\\\n                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\\\\n                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\\n\\n#Setting max_depth, rest are default values\\nparam_dt = en.parameter_set_decision_tree(max_depth = [6])\\n\\nen.train_base_models(['gradient_boosting','decision_tree'],[param_gb, param_dt], save_models = True)\\n\\nweights = en.assign_weights(weights = 'default', hyper_parameter_optimisation = True)\\n\\n#Stacking\\nen.train_ensemble_models(stack_model_list = ['gradient_boosting'], stack_parameters_list = [param_gb], \\n                      perform_weighted_average = True, weights_list = weights)\\n\\ntest_models(data_test)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'en' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Setting max_depth, rest are default values\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6])\n",
    "\n",
    "en.train_base_models(['gradient_boosting','decision_tree'],[param_gb, param_dt], save_models = True)\n",
    "\n",
    "weights = en.assign_weights(weights = 'default', hyper_parameter_optimisation = True)\n",
    "\n",
    "#Stacking\n",
    "en.train_ensemble_models(stack_model_list = ['gradient_boosting'], stack_parameters_list = [param_gb], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "test_models(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y', encode ='binary', split = True, stratify = False, split_size = 0.1)\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "#Hyper Parameter Optimisation (gamma and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                                gamma = [0, 1, 3, 5, 7], eta = [0.1, 0.3], \\\n",
    "                                                max_depth = [5, 10, 15])\n",
    "\n",
    "#Setting max_depth, splitter, presort rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - splitter\n",
    "param_dt_1 = en.parameter_set_decision_tree(max_depth = [6, 10, 12, 15], splitter = ['best', 'random'], \\\n",
    "                                          presort = [True])\n",
    "#Default Values\n",
    "param_dt_2 = en.parameter_set_decision_tree()\n",
    "\n",
    "en.train_base_models(['decision_tree','decision_tree', 'gradient_boosting'], \\\n",
    "                     [param_dt_1, param_dt_2, param_gb])\n",
    "\n",
    "weights = en.assign_weights(weights = [[2],[1],[3]], hyper_parameter_optimisation = False)\n",
    "\n",
    "\n",
    "en.train_ensemble_models(['gradient_boosting'], [param_gb],\n",
    "                      ['gradient_boosting'],[param_gb], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(3)\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb_1 = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Hyper Parameter Optimisation (gamma and eta)\n",
    "param_gb_2 = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                                gamma = [0, 1, 3, 5, 7], eta = [0.1, 0.3], \\\n",
    "                                                max_depth = [5, 10, 15], colsample_bylevel = [0.1])\n",
    "\n",
    "\n",
    "#Setting max_depth, rest are default values\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6])\n",
    "\n",
    "#Setting max_depth, n_estimators, max_features, rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - n_estimators\n",
    "param_rf = en.parameter_set_random_forest(max_depth = [6, 10, 12, 15], n_estimators = [10, 20, 30], \\\n",
    "                                          max_features = ['log2'])\n",
    "\n",
    "#Setting penalty, C, rest are default values\n",
    "#Hyper parameter optimisation - penalty\n",
    "#Hyper parameter optimisation - C\n",
    "param_lor = en.parameter_set_logistic_regression(penalty = ['l1','l2'], C = [1.0, 2.0, 3.0, 5.0, 10.0])\n",
    "\n",
    "#Setting fit_intercept, rest are default values\n",
    "param_lr = en.parameter_set_linear_regression(fit_intercept = [False])\n",
    "\n",
    "#Setting dim_layer, activation, rest are default values\n",
    "#Hyper parameter optimisation : dim_layer - Layer1 and Layer 2\n",
    "#Hyper parameter optimisation : activation - Layer1 and Layer 2\n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = True, \\\n",
    "                                                    dim_layer = [[32,64,128], [32,64], [1]], \\\n",
    "                                                   activation = [['sigmoid','relu'], \\\n",
    "                                                                 ['sigmoid'], ['sigmoid','relu']], \\\n",
    "                                                   optimizer = 'rmsprop')\n",
    "\n",
    "\n",
    "\n",
    "en.train_base_models(['random_forest','multi_layer_perceptron', 'gradient_boosting', \\\n",
    "                      'logistic_regression','linear_regression', 'decision_tree'], \\\n",
    "                     [param_rf, param_mlp, param_gb_1, param_lor, param_lr, param_dt])\n",
    "\n",
    "weights = en.assign_weights(weights = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6],\\\n",
    "                                    [1,2,3,4,5,6]], hyper_parameter_optimisation = True)\n",
    "\n",
    "#Setting penalty, rest are default values\n",
    "param_lor_ens = en.parameter_set_logistic_regression(penalty = ['l2'])\n",
    "\n",
    "#Setting max_depth, splitter, presort rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - splitter\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6, 10, 12, 15], splitter = ['best', 'random'], \\\n",
    "                                          presort = [True])\n",
    "\n",
    "\n",
    "en.train_ensemble_models(['gradient_boosting','logistic_regression'], [param_gb,param_lor_ens],\n",
    "                      ['gradient_boosting','decision_tree','logistic_regression'],[param_gb,param_dt,\\\n",
    "                                                                                   param_lor_ens], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
