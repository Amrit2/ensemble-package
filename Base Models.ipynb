{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.preprocessing import Imputer, PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "\n",
    "#Encoding the data, encoding the string values into numerical values\n",
    "encode = preprocessing.LabelEncoder()\n",
    "\n",
    "#Selcting the columns of string data type\n",
    "names=Data.select_dtypes(include=['object'])\n",
    "\n",
    "#Function that encodes the string values to numerical values\n",
    "def enc(data,column):\n",
    "    data[column] = encode.fit_transform(data[column])\n",
    "    return data\n",
    "for column in names:\n",
    "        Data=enc(Data,column)\n",
    "        \n",
    "#Data.job = encode.fit_transform(Data.job)\n",
    "#Data.marital = encode.fit_transform(Data.marital)\n",
    "#Data.education = encode.fit_transform(Data.education)\n",
    "#Data.default = encode.fit_transform(Data.default)\n",
    "#Data.housing = encode.fit_transform(Data.housing)\n",
    "#Data.loan = encode.fit_transform(Data.loan)\n",
    "#Data.contact = encode.fit_transform(Data.contact)\n",
    "#Data.month = encode.fit_transform(Data.month)\n",
    "#Data.day_of_week = encode.fit_transform(Data.day_of_week)\n",
    "#Data.poutcome = encode.fit_transform(Data.poutcome)\n",
    "#Data.y = encode.fit_transform(Data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict_XGB\n",
    "#predict_multi_layer_perceptron=0\n",
    "#predict_decision_tree=0\n",
    "#predict_random_forest=0\n",
    "#predict_linear_regression=0\n",
    "#predict_logistic_regression_L2=0\n",
    "#predict_logistic_regression_L1=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_boosting(train_X,train_Y,cross_val_X,cross_val_Y):\n",
    "    #Gradient Boosting (XGBoost)\n",
    "    param = {}\n",
    "    #Setting Parameters for the Booster\n",
    "    param['booster'] = 'gbtree'\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param[\"eval_metric\"] = \"auc\"\n",
    "    param['eta'] = 0.3\n",
    "    param['gamma'] = 0\n",
    "    param['max_depth'] = 6\n",
    "    param['min_child_weight']=1\n",
    "    param['max_delta_step'] = 0\n",
    "    param['subsample']= 1\n",
    "    param['colsample_bytree']=1\n",
    "    param['silent'] = 1\n",
    "    param['seed'] = 0\n",
    "    param['base_score'] = 0.5\n",
    "    param['lambda_bias']=1\n",
    "    dtrain = xgb.DMatrix(train_X,label=train_Y)\n",
    "    dcross_val = xgb.DMatrix(cross_val_X,label=cross_val_Y)\n",
    "    gradient_boosting = xgb.train(param, dtrain)\n",
    "    #redict=XGB.predict(dcross_val)\n",
    "    #predict[(predict>=0.5)]=1\n",
    "    #predict[(predict<0.5)]=0\n",
    "    predict=gradient_boosting.predict(dcross_val)\n",
    "    #The AUC error (Cross Validation Data)\n",
    "    auc=roc_auc_score(cross_val_Y,predict)\n",
    "    return {'auc':auc, 'predict':predict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_layer_perceptron(train_X,train_Y,cross_val_X,cross_val_Y):\n",
    "    #Multi Layer Perceptron\n",
    "    multi_layer_perceptron = Sequential()\n",
    "    multi_layer_perceptron.add(Dense(output_dim=64, input_dim=20, init='uniform', activation='sigmoid'))\n",
    "    multi_layer_perceptron.add(Dense(output_dim=1, input_dim=64,activation='sigmoid',))\n",
    "    multi_layer_perceptron.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    multi_layer_perceptron.fit(train_X.as_matrix(), train_Y.as_matrix(), nb_epoch=5, batch_size=128)\n",
    "    predict=multi_layer_perceptron.predict_on_batch(cross_val_X)\n",
    "    #The AUC (Cross Validation Data)\n",
    "    auc=roc_auc_score(cross_val_Y,predict)\n",
    "    return {'auc':auc, 'predict':predict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree(train_X,train_Y,cross_val_X,cross_val_Y):\n",
    "    #Decision Tree\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=6)\n",
    "    decision_tree.fit(train_X,train_Y)\n",
    "    #The AUC (Cross Validation Data)\n",
    "    predict=decision_tree.predict_proba(cross_val_X)[:,1]\n",
    "    auc=roc_auc_score(cross_val_Y,predict)\n",
    "    return {'auc':auc, 'predict':predict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(train_X,train_Y,cross_val_X,cross_val_Y):\n",
    "    #Random Forest (Deafult=10 Trees)\n",
    "    random_forest = RandomForestClassifier()\n",
    "    random_forest.fit(train_X,train_Y)\n",
    "    #The AUC (Cross Validation Data)\n",
    "    predict=random_forest.predict_proba(cross_val_X)[:,1]\n",
    "    auc=roc_auc_score(cross_val_Y,predict)\n",
    "    return {'auc':auc, 'predict':predict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(train_X,train_Y,cross_val_X,cross_val_Y):\n",
    "    #Linear Regression\n",
    "    predict=list()\n",
    "    linear_regression = linear_model.LinearRegression()\n",
    "    linear_regression.fit(train_X,train_Y)\n",
    "    predict=linear_regression.predict(cross_val_X)\n",
    "    #predict[(predict>=0.5)]=1\n",
    "    #predict[(predict<0.5)]=0\n",
    "    #The AUC (Cross Validation Data)\n",
    "    auc=roc_auc_score(cross_val_Y,predict)\n",
    "    return {'auc':auc, 'predict':predict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(train_X,train_Y,cross_val_X,cross_val_Y,penalty):\n",
    "    #Logistic Regression (Default=l2)\n",
    "    logistic_regression = linear_model.LogisticRegression(penalty=penalty)\n",
    "    logistic_regression.fit(train_X,train_Y)\n",
    "    if(penalty=='l2'):\n",
    "        predict=logistic_regression.predict_proba(cross_val_X)[:,1]\n",
    "        #The AUC (Cross Validation Data)\n",
    "        auc=roc_auc_score(cross_val_Y,predict)\n",
    "    else:\n",
    "        predict=logistic_regression.predict_proba(cross_val_X)[:,1]\n",
    "        #The AUC (Cross Validation Data)\n",
    "        auc=roc_auc_score(cross_val_Y,predict)\n",
    "        \n",
    "    return {'auc':auc, 'predict':predict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric_linear_regression=list()\n",
    "avg_linear_regeression=0\n",
    "metric_logistic_regression_L2=list()\n",
    "avg_logistic_regression_L2=0\n",
    "metric_logistic_regression_L1=list()\n",
    "avg_logistic_regression_L1=0\n",
    "metric_decision_tree=list()\n",
    "avg_decision_tree=0\n",
    "metric_random_forest=list()\n",
    "avg_random_forest=0\n",
    "metric_multi_layer_perceptron=list()\n",
    "avg_multi_layer_perceptron=0\n",
    "metric_gradient_boosting=list()\n",
    "avg_gradient_boosting=0\n",
    "metric_XGB=list()\n",
    "avg_XGB=0\n",
    "metric_a=list()\n",
    "avg_a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cross Validation using Stratified K Fold\n",
    "kf = StratifiedKFold(Data['y'], n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.3638 - acc: 0.8873     \n",
      "Epoch 2/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.3236 - acc: 0.8873     \n",
      "Epoch 3/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.3078 - acc: 0.8873     \n",
      "Epoch 4/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.2950 - acc: 0.8873     \n",
      "Epoch 5/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.2869 - acc: 0.8873     \n",
      "Epoch 1/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.3767 - acc: 0.8510     \n",
      "Epoch 2/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.2894 - acc: 0.8873     \n",
      "Epoch 3/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.2699 - acc: 0.8875     \n",
      "Epoch 4/5\n",
      "32950/32950 [==============================] - 0s - loss: 0.2604 - acc: 0.8881     \n",
      "Epoch 5/5\n",
      "12160/32950 [==========>...................] - ETA: 0s - loss: 0.2559 - acc: 0.8895"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-504-d8b78160d511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#Multi Layer Perceptron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#The AUC (Cross Validation Data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmetric_multi_layer_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_layer_perceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_val_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_val_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-494-8eabc67dcd3a>\u001b[0m in \u001b[0;36mmulti_layer_perceptron\u001b[1;34m(train_X, train_Y, cross_val_X, cross_val_Y)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmulti_layer_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmulti_layer_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmulti_layer_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mpredict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_layer_perceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#The AUC (Cross Validation Data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    773\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                     raise Exception('TypeError while preparing batch. '\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mslice_X\u001b[1;34m(X, start, stop)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_index, cross_val_index in kf:\n",
    "    \n",
    "    #Selecting the data\n",
    "    train, cross_val = Data.iloc[train_index], Data.iloc[cross_val_index]\n",
    "    train_Y=train['y']\n",
    "    train_X=train.drop(['y'],axis=1)\n",
    "    cross_val_Y=cross_val['y']\n",
    "    cross_val_X=cross_val.drop(['y'],axis=1)\n",
    "    \n",
    "  \n",
    "    #Gradient Boosting (XGBoost)\n",
    "    #The AUC error (Cross Validation Data)\n",
    "    metric_XGB.append(gradient_boosting(train_X,train_Y,cross_val_X,cross_val_Y)['auc'])\n",
    "    \n",
    "\n",
    "    \n",
    "    #Multi Layer Perceptron\n",
    "    #The AUC (Cross Validation Data)\n",
    "    metric_multi_layer_perceptron.append(multi_layer_perceptron(train_X,train_Y,cross_val_X,cross_val_Y)['auc'])\n",
    "\n",
    "\n",
    "    #Decision Tree)\n",
    "    #The AUC (Cross Validation Data)\n",
    "    metric_decision_tree.append(decision_tree(train_X,train_Y,cross_val_X,cross_val_Y)['auc'])\n",
    "    \n",
    "    \n",
    "    #Random Forest (Deafult=10 Trees)\n",
    "    #The AUC (Cross Validation Data)\n",
    "    metric_random_forest.append(random_forest(train_X,train_Y,cross_val_X,cross_val_Y)['auc'])\n",
    "    \n",
    "    #Scaling the data\n",
    "    train_X=preprocessing.StandardScaler().fit_transform(train_X)\n",
    "    cross_val_X=preprocessing.StandardScaler().fit_transform(cross_val_X)\n",
    "    \n",
    "    #Linear Regression\n",
    "    #The AUC (Cross Validation Data)\n",
    "    metric_linear_regression.append(linear_regression(train_X,train_Y,cross_val_X,cross_val_Y)['auc'])\n",
    "    \n",
    "    #Logistic Regression (Default=l2)\n",
    "    #The AUC (Cross Validation Data)\n",
    "    metric_logistic_regression_L2.append(logistic_regression(train_X,train_Y,cross_val_X,cross_val_Y,'l2')['auc'])\n",
    "    \n",
    "    #Logistic Regression-L1\n",
    "    #The AUC (Cross Validation Data)\n",
    "    metric_logistic_regression_L1.append(logistic_regression(train_X,train_Y,cross_val_X,cross_val_Y,'l1')['auc'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "avg_linear_regression=np.mean(metric_linear_regression)\n",
    "avg_logistic_regression_L2=np.mean(metric_logistic_regression_L2)\n",
    "avg_logistic_regression_L1=np.mean(metric_logistic_regression_L1)\n",
    "avg_decision_tree=np.mean(metric_decision_tree)\n",
    "avg_random_forest=np.mean(metric_random_forest)\n",
    "avg_multi_layer_perceptron=np.mean(metric_multi_layer_perceptron)\n",
    "avg_gradient_boosting=np.mean(metric_gradient_boosting)\n",
    "avg_XGB=np.mean(metric_XGB)\n",
    "avg_a=np.mean(metric_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AUC (Linear Regression)\n",
      " 0.927991800463\n",
      " AUC (Logistic Regression - L2)\n",
      " 0.92949881372\n",
      " AUC (Logistic Regression - L1)\n",
      " 0.929511786691\n",
      " AUC (Decision Tree)\n",
      " 0.925999936182\n",
      " AUC (Random Forest)\n",
      " 0.918062201515\n",
      " AUC (Multi Layer Perceptron)\n",
      " 0.879679680464\n",
      " AUC (Gradient Boosting - XGBoost)\n",
      " 0.948288503607\n"
     ]
    }
   ],
   "source": [
    "print (' AUC (Linear Regression)\\n',avg_linear_regression)\n",
    "print (' AUC (Logistic Regression - L2)\\n',avg_logistic_regression_L2)\n",
    "print (' AUC (Logistic Regression - L1)\\n',avg_logistic_regression_L1)\n",
    "print (' AUC (Decision Tree)\\n',avg_decision_tree)\n",
    "print (' AUC (Random Forest)\\n',avg_random_forest)\n",
    "print (' AUC (Multi Layer Perceptron)\\n',avg_multi_layer_perceptron)\n",
    "print (' AUC (Gradient Boosting - XGBoost)\\n',avg_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
