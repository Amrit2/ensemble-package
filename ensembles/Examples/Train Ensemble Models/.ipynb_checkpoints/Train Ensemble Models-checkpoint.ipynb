{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import ensembles as en\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from sklearn import datasets, linear_model, preprocessing, grid_search\n",
    "from sklearn.preprocessing import Imputer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, accuracy_score, \\\n",
    "mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials \n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 21)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "gradient_boosting \n",
      " 0.945293510106\n",
      "decision_tree \n",
      " 0.906922348135\n",
      "\n",
      "TRAINING ENSEMBLE MODELS\n",
      "\n",
      "Weighted Average\n",
      "Weight [5, 0]\n",
      "Metric Score 0.945293510106\n",
      "\n",
      "TESTING PHASE\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "gradient_boosting \n",
      " 0.947718871697\n",
      "decision_tree \n",
      " 0.910751522609\n",
      "\n",
      "TESTING ENSEMBLE MODELS\n",
      "\n",
      "Stacking gradient_boosting \n",
      " 0.946814184107\n",
      "Weighted Average [5, 0] \n",
      " 0.947718871697\n",
      "CPU times: user 2.49 s, sys: 220 ms, total: 2.71 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Setting max_depth, rest are default values\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6])\n",
    "\n",
    "en.train_base_models(['gradient_boosting','decision_tree'],[param_gb, param_dt], save_models = True)\n",
    "\n",
    "weights = en.assign_weights(weights = 'default', hyper_parameter_optimisation = True)\n",
    "\n",
    "#Stacking\n",
    "en.train_ensemble_models(stack_model_list = ['gradient_boosting'], stack_parameters_list = [param_gb], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 36)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "Epoch 1/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 2/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 3/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 4/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 5/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 6/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 7/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 8/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 9/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "Epoch 10/10\n",
      "14415/14415 [==============================] - 0s - loss: 14.3022 - acc: 0.1127     \n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "10656/14416 [=====================>........] - ETA: 0slinear_regression \n",
      " 0.932549630773\n",
      "logistic_regression \n",
      " 0.935544113162\n",
      "multi_layer_perceptron \n",
      " 0.5\n",
      "\n",
      "TRAINING ENSEMBLE MODELS\n",
      "\n",
      "\n",
      "TESTING PHASE\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "10720/12357 [=========================>....] - ETA: 0slinear_regression \n",
      " 0.934629254\n",
      "logistic_regression \n",
      " 0.93571276947\n",
      "multi_layer_perceptron \n",
      " 0.5\n",
      "\n",
      "TESTING ENSEMBLE MODELS\n",
      "\n",
      "Blending logistic_regression \n",
      " 0.935907223087\n",
      "CPU times: user 8.67 s, sys: 644 ms, total: 9.32 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y',encode = 'binary')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(4)\n",
    "\n",
    "#Setting penalty, rest are default values\n",
    "param_lor = en.parameter_set_logistic_regression(penalty = ['l1'])\n",
    "\n",
    "#Setting fit_intercept, rest are default values\n",
    "param_lr = en.parameter_set_linear_regression(fit_intercept = [False])\n",
    "\n",
    "#Setting dim_layer, activation, rest are deafault values\n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = False, \\\n",
    "                                                    dim_layer = [[32], [64], [32], [1]], \\\n",
    "                                                   activation = [['sigmoid'], ['relu'], ['sigmoid'], ['relu']])\n",
    "\n",
    "#MLP does not work well with binary encode (changes to be made)\n",
    "en.train_base_models(['linear_regression','logistic_regression', 'multi_layer_perceptron'], \\\n",
    "                     [param_lr, param_lor, param_mlp])\n",
    "\n",
    "#Setting penalty, rest are default values\n",
    "param_lor_ens = en.parameter_set_logistic_regression(penalty = ['l2'])\n",
    "\n",
    "en.train_ensemble_models(blend_model_list = ['logistic_regression'], blend_parameters_list = [param_lor_ens], \n",
    "                      perform_weighted_average = False)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (4119, 36)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "decision_tree \n",
      " 0.922828282341\n",
      "decision_tree \n",
      " 0.716768227779\n",
      "gradient_boosting \n",
      " 0.946306227052\n",
      "\n",
      "TRAINING ENSEMBLE MODELS\n",
      "\n",
      "Weighted Average\n",
      "Weight [2, 1, 3]\n",
      "Metric Score 0.942348069366\n",
      "\n",
      "TESTING PHASE\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "decision_tree \n",
      " 0.930264257081\n",
      "decision_tree \n",
      " 0.727851866988\n",
      "gradient_boosting \n",
      " 0.950314019388\n",
      "\n",
      "TESTING ENSEMBLE MODELS\n",
      "\n",
      "Stacking gradient_boosting \n",
      " 0.949605146913\n",
      "Blending gradient_boosting \n",
      " 0.950797819594\n",
      "Weighted Average [2, 1, 3] \n",
      " 0.948052779297\n",
      "CPU times: user 7.36 s, sys: 344 ms, total: 7.7 s\n",
      "Wall time: 10min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y', encode ='binary', split = True, stratify = False, split_size = 0.1)\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "#Hyper Parameter Optimisation (gamma and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                                gamma = [0, 1, 3, 5, 7], eta = [0.1, 0.3], \\\n",
    "                                                max_depth = [5, 10, 15])\n",
    "\n",
    "#Setting max_depth, splitter, presort rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - splitter\n",
    "param_dt_1 = en.parameter_set_decision_tree(max_depth = [6, 10, 12, 15], splitter = ['best', 'random'], \\\n",
    "                                          presort = [True])\n",
    "#Default Values\n",
    "param_dt_2 = en.parameter_set_decision_tree()\n",
    "\n",
    "en.train_base_models(['decision_tree','decision_tree', 'gradient_boosting'], \\\n",
    "                     [param_dt_1, param_dt_2, param_gb])\n",
    "\n",
    "weights = en.assign_weights(weights = [2, 1, 3], hyper_parameter_optimisation = False)\n",
    "\n",
    "\n",
    "en.train_ensemble_models(['gradient_boosting'], [param_gb],\n",
    "                      ['gradient_boosting'],[param_gb], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 21)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "Epoch 1/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.6683 - acc: 0.8476     \n",
      "Epoch 2/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.6694 - acc: 0.8687     \n",
      "Epoch 3/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 4/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 5/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 6/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 7/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 8/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 9/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 10/10\n",
      "9609/9609 [==============================] - 0s - loss: 14.1472 - acc: 0.0000e+00     \n",
      "Epoch 1/10\n",
      "9610/9610 [==============================] - 1s - loss: 1.9163 - acc: 0.8759     \n",
      "Epoch 2/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "9610/9610 [==============================] - 0s - loss: 1.8164 - acc: 0.8873     \n",
      "Epoch 1/10\n",
      "9611/9611 [==============================] - 1s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 2/10\n",
      "9611/9611 [==============================] - 1s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "9611/9611 [==============================] - 1s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "9611/9611 [==============================] - 1s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "9611/9611 [==============================] - 0s - loss: 1.8162 - acc: 0.8873     \n",
      "Epoch 1/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8185 - acc: 0.8811     \n",
      "Epoch 2/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 3/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 4/10\n",
      "14415/14415 [==============================] - 0s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 5/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 6/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 7/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 8/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 9/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "Epoch 10/10\n",
      "14415/14415 [==============================] - 1s - loss: 1.8159 - acc: 0.8873     \n",
      "14048/14415 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "12032/14416 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest \n",
      " 0.915610236501\n",
      "multi_layer_perceptron \n",
      " 0.523591368682\n",
      "gradient_boosting \n",
      " 0.94703275812\n",
      "\n",
      "TRAINING ENSEMBLE MODELS\n",
      "\n",
      "\n",
      "TESTING PHASE\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "10368/12357 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest \n",
      " 0.920414026343\n",
      "multi_layer_perceptron \n",
      " 0.527481118082\n",
      "gradient_boosting \n",
      " 0.945912772353\n",
      "\n",
      "TESTING ENSEMBLE MODELS\n",
      "\n",
      "Stacking gradient_boosting \n",
      " 0.945852595248\n",
      "Stacking decision_tree \n",
      " 0.940171804488\n",
      "Blending decision_tree \n",
      " 0.939711877133\n",
      "CPU times: user 3.39 s, sys: 420 ms, total: 3.81 s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(3)\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Setting n_estimators, criterion, rest are default values\n",
    "#Hyper parameter optimisation - n_estimators\n",
    "param_rf = en.parameter_set_random_forest(n_estimators = [6, 10, 12], criterion = ['entropy'])\n",
    "\n",
    "#Setting dim_layer, activation, rest are default values\n",
    "#Hyper parameter optimisation : dim_layer - Layer1 and Layer 2\n",
    "#Hyper parameter optimisation : activation - Layer1 \n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = True, \\\n",
    "                                                    dim_layer = [[32,64,128], [32,64], [1]], \\\n",
    "                                                   activation = [['sigmoid','relu'], \\\n",
    "                                                                 ['sigmoid'], ['sigmoid','relu']], \\\n",
    "                                                   optimizer = 'sgd')\n",
    "\n",
    "en.train_base_models(['random_forest','multi_layer_perceptron', 'gradient_boosting'], \\\n",
    "                     [param_rf, param_mlp, param_gb])\n",
    "\n",
    "#Setting max_depth, splitter, presort rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - splitter\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6, 10, 12, 15], splitter = ['best', 'random'], \\\n",
    "                                          presort = [True])\n",
    "\n",
    "en.train_ensemble_models(['gradient_boosting','decision_tree'], [param_gb, param_dt],\n",
    "                      ['decision_tree'],[param_dt], \n",
    "                      perform_weighted_average = False)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:178: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/category_encoders/ordinal.py:167: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (41188, 21)\n",
      "Test Data (12357, 21)\n",
      "\n",
      "TRAINING BASE MODELS\n",
      "\n",
      "Epoch 1/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.3407 - acc: 0.8952     \n",
      "Epoch 2/10\n",
      "9609/9609 [==============================] - 1s - loss: 0.2440 - acc: 0.9034     \n",
      "Epoch 3/10\n",
      "9609/9609 [==============================] - 1s - loss: 0.2497 - acc: 0.9082     \n",
      "Epoch 4/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.2515 - acc: 0.9064     \n",
      "Epoch 5/10\n",
      "9609/9609 [==============================] - 1s - loss: 0.2440 - acc: 0.9084     \n",
      "Epoch 6/10\n",
      "9609/9609 [==============================] - 1s - loss: 0.2670 - acc: 0.9093     \n",
      "Epoch 7/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.2622 - acc: 0.9086     \n",
      "Epoch 8/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.2418 - acc: 0.9076     \n",
      "Epoch 9/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.2472 - acc: 0.9108     \n",
      "Epoch 10/10\n",
      "9609/9609 [==============================] - 0s - loss: 0.2579 - acc: 0.9069     \n",
      "Epoch 1/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.3361 - acc: 0.8874     \n",
      "Epoch 2/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2491 - acc: 0.8997     \n",
      "Epoch 3/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2414 - acc: 0.9026     \n",
      "Epoch 4/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2353 - acc: 0.9032     \n",
      "Epoch 5/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2474 - acc: 0.9053     \n",
      "Epoch 6/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2289 - acc: 0.9043     \n",
      "Epoch 7/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2271 - acc: 0.9056     \n",
      "Epoch 8/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2435 - acc: 0.9070     \n",
      "Epoch 9/10\n",
      "9610/9610 [==============================] - 0s - loss: 0.2419 - acc: 0.9062     \n",
      "Epoch 10/10\n",
      "9610/9610 [==============================] - 1s - loss: 0.2319 - acc: 0.9074     \n",
      "Epoch 1/10\n",
      "9611/9611 [==============================] - 1s - loss: 0.3014 - acc: 0.8901     \n",
      "Epoch 2/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2435 - acc: 0.9017     \n",
      "Epoch 3/10\n",
      "9611/9611 [==============================] - 1s - loss: 0.2571 - acc: 0.9027     \n",
      "Epoch 4/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2448 - acc: 0.9053     \n",
      "Epoch 5/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2539 - acc: 0.9076     \n",
      "Epoch 6/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2638 - acc: 0.9072     \n",
      "Epoch 7/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2491 - acc: 0.9075     \n",
      "Epoch 8/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2560 - acc: 0.9071     \n",
      "Epoch 9/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2490 - acc: 0.9058     \n",
      "Epoch 10/10\n",
      "9611/9611 [==============================] - 0s - loss: 0.2713 - acc: 0.9053     \n",
      "Epoch 1/10\n",
      "14415/14415 [==============================] - 1s - loss: 2.5823 - acc: 0.7328     \n",
      "Epoch 2/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2403 - acc: 0.9031     \n",
      "Epoch 3/10\n",
      "14415/14415 [==============================] - 1s - loss: 0.2601 - acc: 0.9049     \n",
      "Epoch 4/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2591 - acc: 0.9052     \n",
      "Epoch 5/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2534 - acc: 0.9068     \n",
      "Epoch 6/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2553 - acc: 0.9095     \n",
      "Epoch 7/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2601 - acc: 0.9047     \n",
      "Epoch 8/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2329 - acc: 0.9069     \n",
      "Epoch 9/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2594 - acc: 0.9041     \n",
      "Epoch 10/10\n",
      "14415/14415 [==============================] - 0s - loss: 0.2301 - acc: 0.9054     \n",
      "14368/14415 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "12640/14416 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest \n",
      " 0.94123934833\n",
      "multi_layer_perceptron \n",
      " 0.93083182762\n",
      "gradient_boosting \n",
      " 0.947415299779\n",
      "logistic_regression \n",
      " 0.926925830337\n",
      "linear_regression \n",
      " 0.927305291253\n",
      "decision_tree \n",
      " 0.918983144869\n",
      "\n",
      "TRAINING ENSEMBLE MODELS\n",
      "\n",
      "Weighted Average\n",
      "Weight [5, 2, 5, 0, 0, 0]\n",
      "Metric Score 0.946883847509\n",
      "\n",
      "TESTING PHASE\n",
      "\n",
      "\n",
      "TESTING/CROSS VALIDATION BASE MODELS\n",
      "\n",
      "11392/12357 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/lib/python3.5/site-packages/keras/models.py:815: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest \n",
      " 0.940707239859\n",
      "multi_layer_perceptron \n",
      " 0.929103901652\n",
      "gradient_boosting \n",
      " 0.946040497193\n",
      "logistic_regression \n",
      " 0.925873796458\n",
      "linear_regression \n",
      " 0.923094904896\n",
      "decision_tree \n",
      " 0.922129483309\n",
      "\n",
      "TESTING ENSEMBLE MODELS\n",
      "\n",
      "Stacking gradient_boosting \n",
      " 0.945079203159\n",
      "Stacking logistic_regression \n",
      " 0.944500592271\n",
      "Blending gradient_boosting \n",
      " 0.946022152512\n",
      "Blending decision_tree \n",
      " 0.93713955978\n",
      "Blending logistic_regression \n",
      " 0.943660274856\n",
      "Weighted Average [5, 2, 5, 0, 0, 0] \n",
      " 0.945867598576\n",
      "CPU times: user 5.22 s, sys: 528 ms, total: 5.75 s\n",
      "Wall time: 11min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data = pd.read_csv('/home/prajwal/Desktop/bank-additional/bank-additional-full.csv',delimiter=';',header=0)\n",
    "data_test = en.data_import(Data, label_output='y')\n",
    "print('Training Data',Data.shape)\n",
    "print('Test Data',data_test.shape)\n",
    "\n",
    "en.metric_set('roc_auc_score')\n",
    "\n",
    "en.set_no_of_layers(3)\n",
    "\n",
    "#Hyper Parameter Optimisation (max_depth and eta)\n",
    "param_gb_1 = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                              max_depth = [5, 10, 15], eta = [0.1, 0.3, 0.5])\n",
    "\n",
    "#Hyper Parameter Optimisation (gamma and eta)\n",
    "param_gb_2 = en.parameter_set_gradient_boosting(hyper_parameter_optimisation = True, \\\n",
    "                                                eval_metric = ['auc'], objective = ['binary:logistic'], \\\n",
    "                                                gamma = [0, 1, 3, 5, 7], eta = [0.1, 0.3], \\\n",
    "                                                max_depth = [5, 10, 15], colsample_bylevel = [0.1])\n",
    "\n",
    "\n",
    "#Setting max_depth, rest are default values\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6])\n",
    "\n",
    "#Setting max_depth, n_estimators, max_features, rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - n_estimators\n",
    "param_rf = en.parameter_set_random_forest(max_depth = [6, 10, 12, 15], n_estimators = [10, 20, 30], \\\n",
    "                                          max_features = ['log2'])\n",
    "\n",
    "#Setting penalty, C, rest are default values\n",
    "#Hyper parameter optimisation - penalty\n",
    "#Hyper parameter optimisation - C\n",
    "param_lor = en.parameter_set_logistic_regression(penalty = ['l1','l2'], C = [1.0, 2.0, 3.0, 5.0, 10.0])\n",
    "\n",
    "#Setting fit_intercept, rest are default values\n",
    "param_lr = en.parameter_set_linear_regression(fit_intercept = [False])\n",
    "\n",
    "#Setting dim_layer, activation, rest are default values\n",
    "#Hyper parameter optimisation : dim_layer - Layer1 and Layer 2\n",
    "#Hyper parameter optimisation : activation - Layer1 and Layer 2\n",
    "param_mlp = en.parameter_set_multi_layer_perceptron(hyper_parameter_optimisation = True, \\\n",
    "                                                    dim_layer = [[32,64,128], [32,64], [1]], \\\n",
    "                                                   activation = [['sigmoid','relu'], \\\n",
    "                                                                 ['sigmoid'], ['sigmoid','relu']], \\\n",
    "                                                   optimizer = 'rmsprop')\n",
    "\n",
    "\n",
    "\n",
    "en.train_base_models(['random_forest','multi_layer_perceptron', 'gradient_boosting', \\\n",
    "                      'logistic_regression','linear_regression', 'decision_tree'], \\\n",
    "                     [param_rf, param_mlp, param_gb_1, param_lor, param_lr, param_dt])\n",
    "\n",
    "weights = en.assign_weights(weights = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6],\\\n",
    "                                    [1,2,3,4,5,6]], hyper_parameter_optimisation = True)\n",
    "\n",
    "#Setting penalty, rest are default values\n",
    "param_lor_ens = en.parameter_set_logistic_regression(penalty = ['l2'])\n",
    "\n",
    "#Setting max_depth, splitter, presort rest are default values\n",
    "#Hyper parameter optimisation - max_depth\n",
    "#Hyper parameter optimisation - splitter\n",
    "param_dt = en.parameter_set_decision_tree(max_depth = [6, 10, 12, 15], splitter = ['best', 'random'], \\\n",
    "                                          presort = [True])\n",
    "\n",
    "\n",
    "en.train_ensemble_models(['gradient_boosting','logistic_regression'], [param_gb,param_lor_ens],\n",
    "                      ['gradient_boosting','decision_tree','logistic_regression'],[param_gb,param_dt,\\\n",
    "                                                                                   param_lor_ens], \n",
    "                      perform_weighted_average = True, weights_list = weights)\n",
    "\n",
    "en.test_models(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
